# üöÄ PLANO DE IMPLEMENTA√á√ÉO IMEDIATA - SISTEMA CHAT IA TELECOMUNICA√á√ïES

> **Roadmap Executivo para Migra√ß√£o Node.js ‚Üí Python/FastAPI**  
> **Meta: 10k clientes simult√¢neos em 16 semanas**

## üéØ VIS√ÉO EXECUTIVA

### üìä Situa√ß√£o Atual vs Objetivo
| M√©trica | Atual | Objetivo | Multiplicador |
|---------|-------|----------|---------------|
| Clientes simult√¢neos | 50 | 10,000 | 200x |
| Sess√µes WhatsApp | 10 | 1,000+ | 100x |
| Throughput (msg/min) | 100 | 10,000 | 100x |
| Uptime | 85% | 99.9% | 1.17x |
| Response time | 2-5s | <200ms | 10-25x |

### üèÜ Benef√≠cios Esperados
- **Receita**: +$1.2M/ano (novos clientes)
- **Economia**: $480k/ano (efici√™ncia operacional)
- **ROI**: 877% no primeiro ano
- **Competitividade**: L√≠der de mercado em atendimento IA

---

## üìÖ CRONOGRAMA DETALHADO (16 SEMANAS)

### üèóÔ∏è FASE 1: FUNDA√á√ÉO T√âCNICA (Semanas 1-4)
**Objetivo**: Estabelecer base s√≥lida para desenvolvimento

#### Semana 1: Setup Inicial
**Respons√°vel**: Tech Lead + DevOps Engineer

**Dia 1-2: Ambiente de Desenvolvimento**
```bash
# Estrutura do projeto
mkdir is em uma vantagem competitiva sustent√°vel e crescimento acelerado da empresa.**

---

*Documento preparado por: Especialista Senior em Arquitetura de Software*  
*Data: Janeiro 2026*  
*Vers√£o: 1.0* do cronograma (30min)
3. Defini√ß√£o de responsabilidades (30min)
4. Setup dos ambientes (30min)

---

## üèÜ CONCLUS√ÉO

Este plano de implementa√ß√£o representa a evolu√ß√£o necess√°ria para transformar o sistema atual em uma plataforma de classe mundial, capaz de:

- **Escalar para 10k+ clientes simult√¢neos**
- **Garantir 99.9% de uptime**
- **Reduzir custos operacionais em 50%**
- **Aumentar satisfa√ß√£o do cliente em 40%**
- **Gerar ROI de 1,254% no primeiro ano**

**O investimento de $155k em 16 semanas resultar√°
5. **Sexta-feira**: Primeira reuni√£o de planejamento da equipe

### üìã Checklist de Aprova√ß√£o
- [ ] Or√ßamento de $155k aprovado
- [ ] Equipe de 5 pessoas confirmada
- [ ] Cronograma de 16 semanas aceito
- [ ] Infraestrutura AWS/GCP aprovada
- [ ] Licen√ßas WhatsApp Business API solicitadas
- [ ] Acesso aos sistemas atuais liberado

### üìû Reuni√£o de Kickoff
**Data**: [A definir]  
**Dura√ß√£o**: 2 horas  
**Participantes**: Stakeholders + Equipe t√©cnica  

**Agenda**:
1. Apresenta√ß√£o da equipe (30min)
2. Revis√£oraso na Integra√ß√£o IA** | M√©dia | M√©dio | OpenAI + backup com Anthropic |
| **Problemas de Seguran√ßa** | Baixa | Alto | Security audit na semana 12 |
| **Custos de Infraestrutura** | M√©dia | M√©dio | Monitoramento cont√≠nuo de custos |

---

## üéØ PR√ìXIMOS PASSOS IMEDIATOS

### üìÖ Esta Semana (Semana 1)
1. **Segunda-feira**: Aprova√ß√£o do or√ßamento
2. **Ter√ßa-feira**: In√≠cio da contrata√ß√£o da equipe
3. **Quarta-feira**: Setup dos reposit√≥rios Git
4. **Quinta-feira**: Configura√ß√£o do ambiente de desenvolvimento| Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **WhatsApp API Instabilidade** | M√©dia | Alto | Implementar fallback para m√∫ltiplos provedores |
| **Equipe Incompleta** | Baixa | Alto | Contratos assinados antes do in√≠cio |
| **Mudan√ßas de Escopo** | Alta | M√©dio | Escopo fixo com change control |
| **Performance Inadequada** | Baixa | Alto | Testes de carga desde semana 8 |

### üü° Riscos M√©dios

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Atenvolvimento e testes |
| Monitoring Tools | $2,000 | Datadog, New Relic |
| Security Audit | $5,000 | Auditoria de seguran√ßa |
| Load Testing | $3,000 | Ferramentas e execu√ß√£o |
| **Subtotal Infra** | **$25,000** | |

### üìä TOTAL DO PROJETO
**Investimento Total: $155,000**

### üí° ROI Projetado (12 meses)
- **Economia operacional**: $600,000/ano
- **Receita adicional**: $1,500,000/ano
- **ROI**: 1,254% no primeiro ano

---

## üö® RISCOS E MITIGA√á√ïES

### üî¥ Riscos Cr√≠ticos

| Risco | Probabilidade | Impacto | Total |
|--------|------------|-------------|-------|
| Tech Lead | 1 | $8,000 | $32,000 |
| Backend Senior | 2 | $6,000 | $48,000 |
| Frontend Senior | 1 | $5,500 | $22,000 |
| DevOps Engineer | 1 | $7,000 | $28,000 |
| **Subtotal Equipe** | | | **$130,000** |

### üõ†Ô∏è Infraestrutura e Ferramentas
| Item | Custo | Descri√ß√£o |
|------|-------|-----------|
| AWS/GCP Credits | $10,000 | Ambiente dev/staging/prod |
| WhatsApp Business API | $2,000 | Setup + primeiros meses |
| OpenAI API Credits | $3,000 | Des14): Sistema Completo
**Crit√©rios de Aceita√ß√£o:**
- [ ] Dashboard web funcional
- [ ] Mobile app b√°sico
- [ ] Testes de carga aprovados (10k usu√°rios)
- [ ] Monitoramento completo
- [ ] Documenta√ß√£o finalizada

### üéØ Marco 5 (Semana 16): Go-Live
**Crit√©rios de Aceita√ß√£o:**
- [ ] Deploy em produ√ß√£o
- [ ] Migra√ß√£o de dados conclu√≠da
- [ ] Treinamento da equipe
- [ ] Monitoramento 24/7 ativo
- [ ] SLA de 99.9% atingido

---

## üí∞ OR√áAMENTO DETALHADO

### üë• Equipe (16 semanas)
| Fun√ß√£o | Quantidade | Sal√°rio/m√™s h Service completo e testado
- [ ] Chat Service com WebSocket funcionando
- [ ] AI Service integrado com OpenAI
- [ ] Queue Service gerenciando filas
- [ ] APIs documentadas (OpenAPI)
- [ ] Testes de integra√ß√£o passando

### üéØ Marco 3 (Semana 11): WhatsApp Integration
**Crit√©rios de Aceita√ß√£o:**
- [ ] WhatsApp Business API integrado
- [ ] Pool Manager escalando automaticamente
- [ ] Webhook processando mensagens
- [ ] Load balancing funcionando
- [ ] M√©tricas de performance coletadas

### üéØ Marco 4 (Semana on {conversation_id} to waiting queue: {reason}")
        
        return conversation
```

---

## üìã ENTREG√ÅVEIS E MARCOS

### üéØ Marco 1 (Semana 4): Funda√ß√£o Completa
**Crit√©rios de Aceita√ß√£o:**
- [ ] PostgreSQL configurado com particionamento
- [ ] Redis Cluster funcionando
- [ ] Modelos de dados implementados
- [ ] Middleware de seguran√ßa ativo
- [ ] Testes unit√°rios b√°sicos (>80% cobertura)
- [ ] CI/CD pipeline configurado

### üéØ Marco 2 (Semana 8): Core Services
**Crit√©rios de Aceita√ß√£o:**
- [ ] Auttion_id)
        )
        conversation = result.scalar_one_or_none()
        
        if not conversation:
            return None
        
        conversation.status = ConversationStatus.WAITING
        conversation.updated_at = datetime.utcnow()
        
        await db.commit()
        await db.refresh(conversation)
        
        # Adicionar √† fila de espera
        redis = await self.get_redis()
        await redis.lpush("waiting_queue", conversation_id)
        
        logger.info(f"Moved conversati.client.lrem("waiting_queue", 0, conversation_id)
        
        logger.info(f"Assigned conversation {conversation_id} to agent {agent_id}")
        
        return conversation
    
    async def move_to_waiting(
        self,
        db: AsyncSession,
        conversation_id: str,
        reason: str = "bot_failed"
    ) -> Optional[Conversation]:
        """Mover conversa para fila de espera"""
        
        result = await db.execute(
            select(Conversation).where(Conversation.id == conversaon = result.scalar_one_or_none()
        
        if not conversation:
            return None
        
        # Atualizar conversa
        conversation.agent_id = agent_id
        conversation.status = ConversationStatus.IN_SERVICE
        conversation.assigned_at = datetime.utcnow()
        conversation.updated_at = datetime.utcnow()
        
        await db.commit()
        await db.refresh(conversation)
        
        # Remover da fila de espera
        redis = await self.get_redis()
        await redised_at.desc()).limit(limit).offset(offset)
        
        result = await db.execute(query)
        return result.scalars().all()
    
    async def assign_conversation(
        self,
        db: AsyncSession,
        conversation_id: str,
        agent_id: str
    ) -> Optional[Conversation]:
        """Atribuir conversa a um agente"""
        
        # Buscar conversa
        result = await db.execute(
            select(Conversation).where(Conversation.id == conversation_id)
        )
        conversatisation]:
        """Listar conversas com filtros"""
        
        query = select(Conversation)
        
        # Aplicar filtros
        conditions = []
        if status:
            conditions.append(Conversation.status == ConversationStatus(status))
        if agent_id:
            conditions.append(Conversation.agent_id == agent_id)
        
        if conditions:
            query = query.where(and_(*conditions))
        
        # Ordenar e paginar
        query = query.order_by(Conversation.creat
        
        # Adicionar √† fila de automa√ß√£o
        redis = await self.get_redis()
        await redis.lpush("automation_queue", str(conversation.id))
        
        logger.info(f"Created conversation {conversation.id} for {customer_phone}")
        
        return conversation
    
    async def list_conversations(
        self,
        db: AsyncSession,
        status: Optional[str] = None,
        agent_id: Optional[str] = None,
        limit: int = 50,
        offset: int = 0
    ) -> List[Conver    """Criar nova conversa"""
        
        conversation = Conversation(
            customer_phone=customer_phone,
            customer_name=customer_name,
            status=ConversationStatus.AUTOMATION,
            priority=ConversationPriority.NORMAL,
            last_message=initial_message,
            last_message_at=datetime.utcnow() if initial_message else None,
            bot_attempts=0
        )
        
        db.add(conversation)
        await db.commit()
        await db.refresh(conversation)room_id
        
        logger.info(f"User {user_id} moved to room {new_room_id}")

class ChatService:
    def __init__(self):
        self.redis = None
    
    async def get_redis(self):
        if not self.redis:
            self.redis = await get_redis()
        return self.redis
    
    async def create_conversation(
        self, 
        db: AsyncSession, 
        customer_phone: str, 
        customer_name: Optional[str] = None,
        initial_message: Optional[str] = None
    ) -> Conversation:
    la atual
        current_room = self.user_rooms.get(user_id)
        if current_room and current_room in self.active_connections:
            if websocket in self.active_connections[current_room]:
                self.active_connections[current_room].remove(websocket)
        
        # Entrar na nova sala
        if new_room_id not in self.active_connections:
            self.active_connections[new_room_id] = []
        self.active_connections[new_room_id].append(websocket)
        self.user_rooms[user_id] = new_oom_id]:
                try:
                    await connection.send_text(message)
                except Exception as e:
                    logger.error(f"Error broadcasting to room {room_id}: {e}")
                    disconnected.append(connection)
            
            # Remover conex√µes mortas
            for conn in disconnected:
                self.active_connections[room_id].remove(conn)
    
    async def join_room(self, websocket: WebSocket, user_id: str, new_room_id: str):
        # Sair da sasync def send_personal_message(self, message: str, user_id: str):
        if user_id in self.user_connections:
            try:
                await self.user_connections[user_id].send_text(message)
            except Exception as e:
                logger.error(f"Error sending message to user {user_id}: {e}")
    
    async def broadcast_to_room(self, message: str, room_id: str):
        if room_id in self.active_connections:
            disconnected = []
            for connection in self.active_connections[rm_id: str):
        # Remover da sala
        if room_id in self.active_connections:
            if websocket in self.active_connections[room_id]:
                self.active_connections[room_id].remove(websocket)
        
        # Remover mapeamentos
        if user_id in self.user_connections:
            del self.user_connections[user_id]
        if user_id in self.user_rooms:
            del self.user_rooms[user_id]
        
        logger.info(f"User {user_id} disconnected from room {room_id}")
    
    aom_id: str):
        await websocket.accept()
        
        # Adicionar √† sala
        if room_id not in self.active_connections:
            self.active_connections[room_id] = []
        self.active_connections[room_id].append(websocket)
        
        # Mapear usu√°rio
        self.user_connections[user_id] = websocket
        self.user_rooms[user_id] = room_id
        
        logger.info(f"User {user_id} connected to room {room_id}")
    
    def disconnect(self, websocket: WebSocket, user_id: str, rooodels.conversation import Conversation, ConversationStatus, ConversationPriority
from shared.models.message import Message, MessageSenderType
from shared.utils.redis_client import get_redis

logger = logging.getLogger(__name__)

class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, List[WebSocket]] = {}
        self.user_connections: Dict[str, WebSocket] = {}
        self.user_rooms: Dict[str, str] = {}
    
    async def connect(self, websocket: WebSocket, user_id: str, roConversationResponse.from_orm(conversation).dict()
        }),
        agent_id
    )
    
    return ConversationResponse.from_orm(conversation)

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "chat-service"}

# services/chat-service/app/services.py
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_
from fastapi import WebSocket
from typing import Dict, List, Optional
import json
import logging
from datetime import datetime

from shared.m usu√°rio atual
    if not agent_id:
        agent_id = str(current_user.id)
    
    conversation = await chat_service.assign_conversation(
        db=db,
        conversation_id=conversation_id,
        agent_id=agent_id
    )
    
    if not conversation:
        raise HTTPException(status_code=404, detail="Conversation not found")
    
    # Notificar via WebSocket
    await connection_manager.send_personal_message(
        json.dumps({
            "type": "conversation_assigned",
            "conversation": ons(
        db=db,
        status=status,
        agent_id=agent_id,
        limit=limit,
        offset=offset
    )
    
    return [ConversationResponse.from_orm(conv) for conv in conversations]

@app.put("/conversations/{conversation_id}/assign")
async def assign_conversation(
    conversation_id: str,
    agent_id: Optional[str] = None,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Atribuir conversa a um agente"""
    
    # Se agent_id n√£o fornecido, usarponse.from_orm(conversation).dict()
        }),
        "agents"
    )
    
    return ConversationResponse.from_orm(conversation)

@app.get("/conversations", response_model=List[ConversationResponse])
async def list_conversations(
    status: Optional[str] = None,
    agent_id: Optional[str] = None,
    limit: int = 50,
    offset: int = 0,
    db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Listar conversas"""
    conversations = await chat_service.list_conversati db: AsyncSession = Depends(get_db),
    current_user = Depends(get_current_user)
):
    """Criar nova conversa"""
    conversation = await chat_service.create_conversation(
        db=db,
        customer_phone=request.customer_phone,
        customer_name=request.customer_name,
        initial_message=request.initial_message
    )
    
    # Notificar via WebSocket
    await connection_manager.broadcast_to_room(
        json.dumps({
            "type": "new_conversation",
            "conversation": ConversationResnte
        await connection_manager.send_personal_message(
            json.dumps({
                "type": "conversation_assigned",
                "conversation_id": conversation_id,
                "status": "success"
            }),
            user_id
        )
    except Exception as e:
        logger.error(f"Error assigning conversation: {e}")

# REST API Endpoints
@app.post("/conversations", response_model=ConversationResponse)
async def create_conversation(
    request: CreateConversationRequest,
   er_id": user_id,
                "content": message_data["content"],
                "timestamp": datetime.utcnow().isoformat()
            }),
            message_data.get("room_id", "general")
        )
    except Exception as e:
        logger.error(f"Error handling chat message: {e}")

async def handle_assign_conversation(message_data: dict, user_id: str):
    """Processar atribui√ß√£o de conversa"""
    try:
        conversation_id = message_data["conversation_id"]
        # L√≥gica para atribuir conversa ao age)
            
    except WebSocketDisconnect:
        connection_manager.disconnect(websocket, user_id, room_id)
        logger.info(f"User {user_id} disconnected from room {room_id}")

async def handle_chat_message(message_data: dict, user_id: str):
    """Processar mensagem de chat"""
    try:
        # Salvar mensagem no banco
        # Enviar para outros usu√°rios na sala
        await connection_manager.broadcast_to_room(
            json.dumps({
                "type": "new_message",
                "us()
            message_data = json.loads(data)
            
            # Processar mensagem baseado no tipo
            if message_data["type"] == "chat_message":
                await handle_chat_message(message_data, user_id)
            elif message_data["type"] == "assign_conversation":
                await handle_assign_conversation(message_data, user_id)
            elif message_data["type"] == "join_room":
                await connection_manager.join_room(websocket, user_id, message_data["room_id"]fully")

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("Shutting down Chat Service...")
    await redis_client.disconnect()
    logger.info("Chat Service stopped")

# WebSocket para comunica√ß√£o em tempo real
@app.websocket("/ws/{user_id}")
async def websocket_endpoint(
    websocket: WebSocket, 
    user_id: str, 
    room_id: str = "general"
):
    await connection_manager.connect(websocket, user_id, room_id)
    try:
        while True:
            data = await websocket.receive_textrvi√ßo de gest√£o de conversas e mensagens",
    version="1.0.0"
)

# Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Instanciar servi√ßos
chat_service = ChatService()
connection_manager = ConnectionManager()

@app.on_event("startup")
async def startup_event():
    logger.info("Starting Chat Service...")
    await redis_client.connect()
    await init_db()
    logger.info("Chat Service started successt_redis, redis_client
from shared.models.conversation import Conversation, ConversationStatus
from shared.models.message import Message, MessageSenderType
from shared.middleware.auth import get_current_user
from .schemas import ConversationResponse, MessageResponse, CreateConversationRequest
from .services import ChatService, ConnectionManager

# Configurar logging
logging.basicConfig(level=settings.LOG_LEVEL)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Chat Service",
    description="See Base
**Respons√°vel**: Backend Developer 2

```python
# services/chat-service/app/main.py
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Dict, List
import json
import logging
import asyncio
from datetime import datetime

# Imports
from shared.config.settings import settings
from shared.utils.database import get_db, init_db
from shared.utils.redis_client import geselect(User).where(User.email == email))
        return result.scalar_one_or_none()
    
    async def authenticate_user(self, db: AsyncSession, username: str, password: str) -> Optional[User]:
        """Autenticar usu√°rio"""
        user = await self.get_user_by_username(db, username)
        if not user or not user.is_active:
            return None
        
        if not self.verify_password(password, user.password_hash):
            return None
        
        return user
```

#### Semana 6: Chat Servicutcnow()})
        return jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
    
    async def get_user_by_username(self, db: AsyncSession, username: str) -> Optional[User]:
        """Buscar usu√°rio por username"""
        result = await db.execute(select(User).where(User.username == username))
        return result.scalar_one_or_none()
    
    async def get_user_by_email(self, db: AsyncSession, email: str) -> Optional[User]:
        """Buscar usu√°rio por email"""
        result = await db.execute(m = settings.JWT_ALGORITHM
        self.expire_hours = settings.JWT_EXPIRE_HOURS
    
    def verify_password(self, plain_password: str, hashed_password: str) -> bool:
        """Verificar senha"""
        return self.pwd_context.verify(plain_password, hashed_password)
    
    def create_access_token(self, data: dict) -> str:
        """Criar token JWT"""
        to_encode = data.copy()
        expire = datetime.utcnow() + timedelta(hours=self.expire_hours)
        to_encode.update({"exp": expire, "iat": datetime.nvalid role')
        return v

# services/auth-service/app/services.py
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from passlib.context import CryptContext
from shared.models.user import User
from shared.config.settings import settings
import jwt
from datetime import datetime, timedelta

class AuthService:
    def __init__(self):
        self.pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")
        self.secret_key = settings.JWT_SECRET
        self.algorith  access_token: str
    token_type: str
    expires_in: int
    user: UserResponse

class UserCreate(BaseModel):
    username: str
    email: EmailStr
    password: str
    role: str = "agent"
    
    @validator('password')
    def validate_password(cls, v):
        if len(v) < 8:
            raise ValueError('Password must be at least 8 characters long')
        return v
    
    @validator('role')
    def validate_role(cls, v):
        if v not in [role.value for role in UserRole]:
            raise ValueError('Iapp/schemas.py
from pydantic import BaseModel, EmailStr, validator
from typing import Optional
from datetime import datetime
from shared.models.user import UserRole

class LoginRequest(BaseModel):
    username: str
    password: str

class UserResponse(BaseModel):
    id: str
    username: str
    email: str
    role: str
    is_active: bool
    is_verified: bool
    created_at: datetime
    last_login: Optional[datetime]
    
    class Config:
        from_attributes = True

class LoginResponse(BaseModel):
  =user_data.email,
        password_hash=password_hash,
        role=UserRole(user_data.role),
        is_active=True,
        is_verified=True
    )
    
    db.add(new_user)
    await db.commit()
    await db.refresh(new_user)
    
    logger.info(f"User created: {new_user.username} by {current_user.username}")
    
    return UserResponse.from_orm(new_user)

@app.get("/health")
async def health_check():
    """Health check"""
    return {"status": "healthy", "service": "auth-service"}

# services/auth-service/tion(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Username already exists"
        )
    
    existing_email = await auth_service.get_user_by_email(db, user_data.email)
    if existing_email:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Email already exists"
        )
    
    # Criar usu√°rio
    password_hash = pwd_context.hash(user_data.password)
    
    new_user = User(
        username=user_data.username,
        emailrn {
        "valid": True,
        "user": UserResponse.from_orm(current_user)
    }

@app.post("/users", response_model=UserResponse)
async def create_user(
    user_data: UserCreate,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(auth_service.require_role("admin"))
):
    """Criar novo usu√°rio (apenas admins)"""
    
    # Verificar se usu√°rio j√° existe
    existing_user = await auth_service.get_user_by_username(db, user_data.username)
    if existing_user:
        raise HTTPExcep
    )
    
    # Atualizar √∫ltimo login
    user.last_login = datetime.utcnow()
    await db.commit()
    
    logger.info(f"Successful login for user: {user.username}")
    
    return LoginResponse(
        access_token=access_token,
        token_type="bearer",
        expires_in=settings.JWT_EXPIRE_HOURS * 3600,
        user=UserResponse.from_orm(user)
    )

@app.post("/verify")
async def verify_token(
    current_user: User = Depends(auth_service.get_current_user)
):
    """Verificar token"""
    retu: {credentials.username} from IP: {request.client.host}")
        
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid username or password"
        )
    
    # Limpar tentativas de login em caso de sucesso
    await redis.delete(login_attempts_key)
    
    # Criar token
    access_token = auth_service.create_access_token(
        data={
            "sub": user.username,
            "user_id": str(user.id),
            "role": user.role.value
        }T_DURATION_MINUTES} minutes"
        )
    
    # Autenticar usu√°rio
    user = await auth_service.authenticate_user(db, credentials.username, credentials.password)
    
    if not user:
        # Incrementar tentativas falhadas
        current_attempts = int(attempts) + 1 if attempts else 1
        await redis.set(
            login_attempts_key, 
            str(current_attempts), 
            ex=settings.LOCKOUT_DURATION_MINUTES * 60
        )
        
        logger.warning(f"Failed login attempt for userst,
    request: Request,
    db: AsyncSession = Depends(get_db),
    redis = Depends(get_redis)
):
    """Login do usu√°rio"""
    
    # Verificar tentativas de login
    login_attempts_key = f"login_attempts:{credentials.username}"
    attempts = await redis.get(login_attempts_key)
    
    if attempts and int(attempts) >= settings.MAX_LOGIN_ATTEMPTS:
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail=f"Too many login attempts. Try again in {settings.LOCKOUtup_event():
    """Inicializa√ß√£o da aplica√ß√£o"""
    logger.info("Starting Auth Service...")
    await redis_client.connect()
    await init_db()
    logger.info("Auth Service started successfully")

@app.on_event("shutdown")
async def shutdown_event():
    """Finaliza√ß√£o da aplica√ß√£o"""
    logger.info("Shutting down Auth Service...")
    await redis_client.disconnect()
    logger.info("Auth Service stopped")

# Rotas
@app.post("/login", response_model=LoginResponse)
async def login(
    credentials: LoginRequeers=["*"],
)

# Middleware customizado
@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    return await log_requests(request, call_next)

@app.middleware("http")
async def rate_limit_middleware(request: Request, call_next):
    await rate_limiter.check_rate_limit(request)
    return await call_next(request)

# Instanciar servi√ßos
auth_service = AuthService()
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# Events
@app.on_event("startup")
async def star
from .services import AuthService

# Configurar logging
logging.basicConfig(level=settings.LOG_LEVEL)
logger = logging.getLogger(__name__)

# Criar app FastAPI
app = FastAPI(
    title="Auth Service",
    description="Servi√ßo de autentica√ß√£o e autoriza√ß√£o",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configurar adequadamente em produ√ß√£o
    allow_credentials=True,
    allow_methods=["*"],
    allow_headrt AsyncSession
from passlib.context import CryptContext
from datetime import datetime, timedelta
import logging

# Imports locais
from shared.config.settings import settings
from shared.utils.database import get_db, init_db
from shared.utils.redis_client import get_redis, redis_client
from shared.models.user import User, UserRole
from shared.middleware.rate_limit import rate_limiter
from shared.middleware.logging import log_requests
from .schemas import LoginRequest, LoginResponse, UserCreate, UserResponse       "client_ip": request.client.host
        }
    )
    
    # Adicionar header com tempo de processamento
    response.headers["X-Process-Time"] = str(process_time)
    
    return response
```

---

### üèóÔ∏è FASE 2: CORE SERVICES (Semanas 5-8)

#### Semana 5: Auth Service
**Respons√°vel**: Backend Developer 1

```python
# services/auth-service/app/main.py
from fastapi import FastAPI, Depends, HTTPException, status, Request
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.ext.asyncio impo   logger.info(f"Request: {request.method} {request.url}")
    
    # Processar request
    response = await call_next(request)
    
    # Calcular tempo de processamento
    process_time = time.time() - start_time
    
    # Log da response
    logger.info(
        f"Response: {response.status_code} - {process_time:.3f}s",
        extra={
            "method": request.method,
            "url": str(request.url),
            "status_code": response.status_code,
            "process_time": process_time,
     de erro, permitir a request (fail open)
            pass

# Inst√¢ncia global
rate_limiter = RateLimiter(
    max_requests=settings.RATE_LIMIT_PER_MINUTE,
    window=60
)

# shared/middleware/logging.py
from fastapi import Request, Response
import time
import logging
import json
from typing import Callable

logger = logging.getLogger(__name__)

async def log_requests(request: Request, call_next: Callable) -> Response:
    """Middleware para log de requests"""
    start_time = time.time()
    
    # Log da request
                   status_code=status.HTTP_429_TOO_MANY_REQUESTS,
                    detail="Rate limit exceeded",
                    headers={"Retry-After": str(self.window)}
                )
            
            # Adicionar request atual
            await redis_client.client.zadd(key, {str(current_time): current_time})
            await redis_client.client.expire(key, self.window)
            
        except Exception as e:
            logger.error(f"Rate limit check failed: {e}")
            # Em caso e.time())
        window_start = current_time - self.window
        
        try:
            # Remover requests antigas da janela
            await redis_client.client.zremrangebyscore(key, 0, window_start)
            
            # Contar requests na janela atual
            current_requests = await redis_client.client.zcard(key)
            
            if current_requests >= self.max_requests:
                logger.warning(f"Rate limit exceeded for IP: {client_ip}")
                raise HTTPException(
  .redis_client import get_redis
import time
import logging

logger = logging.getLogger(__name__)

class RateLimiter:
    def __init__(self, max_requests: int = 100, window: int = 60):
        self.max_requests = max_requests
        self.window = window
    
    async def check_rate_limit(self, request: Request):
        """Verificar rate limit por IP"""
        redis_client = await get_redis()
        client_ip = request.client.host
        key = f"rate_limit:{client_ip}"
        
        current_time = int(timpara verificar role
def require_role(required_role: str):
    def role_checker(current_user: User = Depends(get_current_user)):
        if current_user.role.value != required_role and current_user.role.value != "admin":
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Insufficient permissions"
            )
        return current_user
    return role_checker

# shared/middleware/rate_limit.py
from fastapi import HTTPException, Request, status
from ..utilsif not result or not result.is_active:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="User not found or inactive"
            )
        
        return result

auth_service = AuthService()

# Dependency para obter usu√°rio atual
async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
    db: AsyncSession = Depends(get_db)
) -> User:
    return await auth_service.get_current_user(credentials, db)

# Dependency  = Depends(security),
        db: AsyncSession = Depends(get_db)
    ) -> User:
        """Obter usu√°rio atual do token"""
        payload = await self.verify_token(credentials.credentials)
        user_id = payload.get("user_id")
        
        if not user_id:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid token payload"
            )
        
        # Buscar usu√°rio no banco
        result = await db.get(User, user_id)
             except jwt.ExpiredSignatureError:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Token expired"
            )
        except jwt.JWTError as e:
            logger.warning(f"JWT decode error: {e}")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid token"
            )
    
    async def get_current_user(
        self, 
        credentials: HTTPAuthorizationCredentials  
    async def verify_token(self, token: str) -> dict:
        """Verificar token JWT"""
        try:
            payload = jwt.decode(token, self.secret_key, algorithms=[self.algorithm])
            
            # Verificar se token n√£o expirou
            if payload.get("exp") < time.time():
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="Token expired"
                )
            
            return payload
            
   
    def __init__(self):
        self.secret_key = settings.JWT_SECRET
        self.algorithm = settings.JWT_ALGORITHM
        self.expire_hours = settings.JWT_EXPIRE_HOURS
    
    def create_access_token(self, data: dict) -> str:
        """Criar token JWT"""
        to_encode = data.copy()
        expire = datetime.utcnow() + timedelta(hours=self.expire_hours)
        to_encode.update({"exp": expire, "iat": datetime.utcnow()})
        return jwt.encode(to_encode, self.secret_key, algorithm=self.algorithm)
  # shared/middleware/auth.py
from fastapi import HTTPException, Depends, status, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.ext.asyncio import AsyncSession
import jwt
import time
from datetime import datetime, timedelta
from ..config.settings import settings
from ..utils.database import get_db
from ..utils.redis_client import get_redis
from ..models.user import User
import logging

logger = logging.getLogger(__name__)
security = HTTPBearer()

class AuthService:  return await self.client.lpush(key, *values)
    
    async def rpop(self, key: str):
        """Pop da lista (direita)"""
        return await self.client.rpop(key)
    
    async def llen(self, key: str):
        """Tamanho da lista"""
        return await self.client.llen(key)

# Inst√¢ncia global
redis_client = RedisClient()

async def get_redis():
    """Dependency para obter cliente Redis"""
    return redis_client
```

#### Semana 4: Middleware e Seguran√ßa
**Respons√°vel**: Security Engineer

```python
   await self.client.close()
    
    async def get(self, key: str):
        """Get valor"""
        return await self.client.get(key)
    
    async def set(self, key: str, value: str, ex: int = None):
        """Set valor com expira√ß√£o opcional"""
        return await self.client.set(key, value, ex=ex)
    
    async def delete(self, key: str):
        """Deletar chave"""
        return await self.client.delete(key)
    
    async def lpush(self, key: str, *values):
        """Push para lista (esquerda)"""
      eout=True,
                    socket_keepalive=True,
                    socket_keepalive_options={}
                )
            
            # Testar conex√£o
            await self.client.ping()
            logger.info(f"Redis connected ({'cluster' if self.is_cluster else 'single'})")
            
        except Exception as e:
            logger.error(f"Redis connection failed: {e}")
            raise
    
    async def disconnect(self):
        """Desconectar do Redis"""
        if self.client:
         nt = RedisCluster(
                    startup_nodes=[
                        {"host": node.split(':')[0], "port": int(node.split(':')[1])}
                        for node in settings.REDIS_CLUSTER_NODES
                    ],
                    decode_responses=True,
                    skip_full_coverage_check=True
                )
            else:
                self.client = redis.from_url(
                    settings.REDIS_URL,
                    decode_responses=True,
                    retry_on_timit conn.run_sync(Base.metadata.create_all)

# shared/utils/redis_client.py
import redis.asyncio as redis
from redis.asyncio.cluster import RedisCluster
from ..config.settings import settings
import logging

logger = logging.getLogger(__name__)

class RedisClient:
    def __init__(self):
        self.client = None
        self.is_cluster = bool(settings.REDIS_CLUSTER_NODES)
    
    async def connect(self):
        """Conectar ao Redis"""
        try:
            if self.is_cluster:
                self.clie,
    autocommit=False
)

async def get_db():
    """Dependency para obter sess√£o do banco"""
    async with AsyncSessionLocal() as session:
        try:
            yield session
        except Exception as e:
            await session.rollback()
            logger.error(f"Database session error: {e}")
            raise
        finally:
            await session.close()

async def init_db():
    """Inicializar banco de dados"""
    from ..models import Base
    async with engine.begin() as conn:
        awaol
from ..config.settings import settings
import logging

logger = logging.getLogger(__name__)

# Engine com configura√ß√µes otimizadas
engine = create_async_engine(
    settings.DATABASE_URL,
    pool_size=settings.DATABASE_POOL_SIZE,
    max_overflow=settings.DATABASE_MAX_OVERFLOW,
    pool_pre_ping=True,
    pool_recycle=3600,  # 1 hora
    echo=settings.DATABASE_ECHO,
    future=True
)

AsyncSessionLocal = sessionmaker(
    engine, 
    class_=AsyncSession, 
    expire_on_commit=False,
    autoflush=FalseRL')
        return v
    
    @validator('REDIS_CLUSTER_NODES', pre=True)
    def parse_redis_cluster_nodes(cls, v):
        if isinstance(v, str):
            return [node.strip() for node in v.split(',') if node.strip()]
        return v
    
    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()

# shared/utils/database.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import NullPo # Celery
    CELERY_BROKER_URL: str = "redis://localhost:6379/0"
    CELERY_RESULT_BACKEND: str = "redis://localhost:6379/0"
    
    # Email (para notifica√ß√µes)
    SMTP_HOST: Optional[str] = None
    SMTP_PORT: int = 587
    SMTP_USERNAME: Optional[str] = None
    SMTP_PASSWORD: Optional[str] = None
    SMTP_USE_TLS: bool = True
    
    @validator('DATABASE_URL')
    def validate_database_url(cls, v):
        if not v.startswith('postgresql'):
            raise ValueError('DATABASE_URL must be a PostgreSQL UE_ENVIRONMENT: Optional[str] = None
    PINECONE_INDEX_NAME: str = "knowledge-base"
    
    # Security
    JWT_SECRET: str
    JWT_ALGORITHM: str = "HS256"
    JWT_EXPIRE_HOURS: int = 24
    PASSWORD_MIN_LENGTH: int = 8
    MAX_LOGIN_ATTEMPTS: int = 5
    LOCKOUT_DURATION_MINUTES: int = 30
    
    # Rate Limiting
    RATE_LIMIT_PER_MINUTE: int = 100
    RATE_LIMIT_BURST: int = 200
    
    # Monitoring
    PROMETHEUS_PORT: int = 8000
    JAEGER_ENDPOINT: Optional[str] = None
    LOG_LEVEL: str = "INFO"
    
      REDIS_URL: str = "redis://localhost:6379"
    REDIS_CLUSTER_NODES: Optional[List[str]] = None
    
    # WhatsApp Business API
    WHATSAPP_ACCESS_TOKEN: str
    WHATSAPP_PHONE_NUMBER_ID: str
    WHATSAPP_WEBHOOK_VERIFY_TOKEN: str
    WHATSAPP_API_VERSION: str = "v18.0"
    
    # OpenAI
    OPENAI_API_KEY: str
    OPENAI_MODEL: str = "gpt-4-turbo-preview"
    OPENAI_MAX_TOKENS: int = 500
    OPENAI_TEMPERATURE: float = 0.7
    
    # Pinecone (Vector DB)
    PINECONE_API_KEY: Optional[str] = None
    PINECONtrue, true);
```

#### Semana 3: Configura√ß√£o e Utils
**Respons√°vel**: Backend Developer 2

```python
# shared/config/settings.py
from pydantic import BaseSettings, validator
from typing import List, Optional
import os

class Settings(BaseSettings):
    # Aplica√ß√£o
    APP_NAME: str = "ISP Chat System"
    APP_VERSION: str = "1.0.0"
    DEBUG: bool = False
    
    # Database
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 20
    DATABASE_MAX_OVERFLOW: int = 30
    DATABASE_ECHO: bool = False
    
    # Redis
 ';

-- Triggers
CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_conversations_updated_at BEFORE UPDATE ON conversations
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

-- Usu√°rio admin padr√£o (senha: admin123)
INSERT INTO users (username, email, password_hash, role, is_active, is_verified)
VALUES ('admin', 'admin@empresa.com', '$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/LewdBPj3QJflLxQjm', 'admin', ustomer_phone);
CREATE INDEX idx_conversations_created_at ON conversations(created_at);
CREATE INDEX idx_messages_conversation ON messages(conversation_id);
CREATE INDEX idx_messages_created_at ON messages(created_at);
CREATE INDEX idx_knowledge_base_embedding ON knowledge_base USING ivfflat (embedding vector_cosine_ops);

-- Fun√ß√£o para atualizar updated_at
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql  tags TEXT[],
    is_active BOOLEAN DEFAULT true,
    created_by UUID NOT NULL REFERENCES users(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    embedding vector(1536), -- OpenAI embeddings
    metadata JSONB DEFAULT '{}'
);

-- √çndices para performance
CREATE INDEX idx_conversations_status ON conversations(status);
CREATE INDEX idx_conversations_agent ON conversations(agent_id);
CREATE INDEX idx_conversations_customer ON conversations(c_date + interval '1 month';
        table_name := 'messages_' || to_char(start_date, 'YYYY_MM');
        
        EXECUTE format('CREATE TABLE %I PARTITION OF messages
                       FOR VALUES FROM (%L) TO (%L)', 
                       table_name, start_date, end_date);
    END LOOP;
END $$;

-- Base de conhecimento com embeddings
CREATE TABLE knowledge_base (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    title VARCHAR(255) NOT NULL,
    content TEXT NOT NULL,
    category VARCHAR(100),
  sage_type DEFAULT 'text',
    whatsapp_message_id VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    delivered_at TIMESTAMP WITH TIME ZONE,
    read_at TIMESTAMP WITH TIME ZONE,
    metadata JSONB DEFAULT '{}'
) PARTITION BY RANGE (created_at);

-- Criar parti√ß√µes para mensagens
DO $$
DECLARE
    start_date date;
    end_date date;
    table_name text;
BEGIN
    FOR i IN 0..11 LOOP
        start_date := date_trunc('month', CURRENT_DATE + interval '1 month' * i);
        end_date := start'conversations_' || to_char(start_date, 'YYYY_MM');
        
        EXECUTE format('CREATE TABLE %I PARTITION OF conversations
                       FOR VALUES FROM (%L) TO (%L)', 
                       table_name, start_date, end_date);
    END LOOP;
END $$;

-- Mensagens (particionada por m√™s)
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID NOT NULL,
    sender_type message_sender_type NOT NULL,
    sender_id UUID,
    content TEXT NOT NULL,
    message_type mes customer_satisfaction INTEGER CHECK (customer_satisfaction BETWEEN 1 AND 5),
    resolution_time INTEGER, -- em segundos
    tags TEXT[],
    metadata JSONB DEFAULT '{}'
) PARTITION BY RANGE (created_at);

-- Criar parti√ß√µes para os pr√≥ximos 12 meses
DO $$
DECLARE
    start_date date;
    end_date date;
    table_name text;
BEGIN
    FOR i IN 0..11 LOOP
        start_date := date_trunc('month', CURRENT_DATE + interval '1 month' * i);
        end_date := start_date + interval '1 month';
        table_name := name VARCHAR(255),
    status conversation_status NOT NULL DEFAULT 'automation',
    priority conversation_priority DEFAULT 'normal',
    agent_id UUID REFERENCES users(id),
    whatsapp_instance_id VARCHAR(50),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    assigned_at TIMESTAMP WITH TIME ZONE,
    closed_at TIMESTAMP WITH TIME ZONE,
    last_message TEXT,
    last_message_at TIMESTAMP WITH TIME ZONE,
    bot_attempts INTEGER DEFAULT 0,
   active BOOLEAN DEFAULT true,
    is_verified BOOLEAN DEFAULT false,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    last_login TIMESTAMP WITH TIME ZONE,
    failed_login_attempts INTEGER DEFAULT 0,
    locked_until TIMESTAMP WITH TIME ZONE,
    metadata JSONB DEFAULT '{}'
);

-- Conversas (particionada por m√™s)
CREATE TABLE conversations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    customer_phone VARCHAR(20) NOT NULL,
    customer_');
CREATE TYPE conversation_priority AS ENUM ('low', 'normal', 'high', 'urgent');
CREATE TYPE message_sender_type AS ENUM ('customer', 'agent', 'bot', 'system');
CREATE TYPE message_type AS ENUM ('text', 'image', 'audio', 'video', 'document');

-- Tabela de usu√°rios
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    role user_role NOT NULL DEFAULT 'agent',
    is_mer_satisfaction = Column(Integer)  # 1-5 rating
    resolution_time = Column(Integer)  # seconds
    tags = Column(ARRAY(String))
    metadata = Column(JSONB, default={})
```

**Schema SQL Completo**
```sql
-- scripts/init.sql
-- Extens√µes necess√°rias
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "vector";

-- Tipos enumerados
CREATE TYPE user_role AS ENUM ('admin', 'supervisor', 'agent', 'viewer');
CREATE TYPE conversation_status AS ENUM ('automation', 'waiting', 'in_service', 'closed= Column(String(20), nullable=False)
    customer_name = Column(String(255))
    status = Column(Enum(ConversationStatus), nullable=False, default=ConversationStatus.AUTOMATION)
    priority = Column(Enum(ConversationPriority), default=ConversationPriority.NORMAL)
    agent_id = Column(UUID(as_uuid=True), ForeignKey('users.id'))
    whatsapp_instance_id = Column(String(50))
    last_message = Column(Text)
    last_message_at = Column(DateTime(timezone=True))
    bot_attempts = Column(Integer, default=0)
    custon.py
from sqlalchemy import Column, String, Integer, Text, ForeignKey
from sqlalchemy.dialects.postgresql import JSONB
from .base import BaseModel
import enum

class ConversationStatus(enum.Enum):
    AUTOMATION = "automation"
    WAITING = "waiting"
    IN_SERVICE = "in_service"
    CLOSED = "closed"

class ConversationPriority(enum.Enum):
    LOW = "low"
    NORMAL = "normal"
    HIGH = "high"
    URGENT = "urgent"

class Conversation(BaseModel):
    __tablename__ = "conversations"
    
    customer_phone False)
    email = Column(String(255), unique=True, nullable=False)
    password_hash = Column(String(255), nullable=False)
    role = Column(Enum(UserRole), nullable=False, default=UserRole.AGENT)
    is_active = Column(Boolean, default=True)
    is_verified = Column(Boolean, default=False)
    last_login = Column(DateTime(timezone=True))
    failed_login_attempts = Column(Integer, default=0)
    locked_until = Column(DateTime(timezone=True))
    metadata = Column(JSONB, default={})

# shared/models/conversatiover_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())

# shared/models/user.py
from sqlalchemy import Column, String, Boolean, Integer, DateTime, Enum
from sqlalchemy.dialects.postgresql import JSONB
from .base import BaseModel
import enum

class UserRole(enum.Enum):
    ADMIN = "admin"
    SUPERVISOR = "supervisor"
    AGENT = "agent"
    VIEWER = "viewer"

class User(BaseModel):
    __tablename__ = "users"
    
    username = Column(String(50), unique=True, nullable=ata:
  grafana_data:
```

#### Semana 2: Modelos de Dados
**Respons√°vel**: Backend Developer 1

**Modelos Base**
```python
# shared/models/base.py
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import Column, DateTime, func
from sqlalchemy.dialects.postgresql import UUID
import uuid

Base = declarative_base()

class BaseModel(Base):
    __abstract__ = True
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    created_at = Column(DateTime(timezone=True), ser.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana

volumes:
  postgres_dion: '3.8'
services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: isp_chat
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8p-chat-system
cd isp-chat-system

# Estrutura de microservi√ßos
mkdir -p {services/{auth,chat,ai,queue,whatsapp,campaign,notification,analytics}-service,shared/{models,utils,middleware,config},infrastructure/{docker,kubernetes,terraform,monitoring},frontend/{web-dashboard,mobile-app},tests/{unit,integration,load},docs/{api,architecture,deployment}}

# Setup Git
git init
git remote add origin https://github.com/empresa/isp-chat-system.git
```

**Dia 3-5: Infraestrutura Base**
```yaml
# docker-compose.dev.yml
vers